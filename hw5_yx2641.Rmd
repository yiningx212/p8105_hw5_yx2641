---
title: "Homework 5"
author: "Yining Xiang"
output: pdf_document
---

```{r setup}
library(tidyverse)
library(readr)
library(ggplot2)
library(data.table)
```

## Problem 1

```{r}
homicide_df <- read_csv("homicide-data.csv")
homicide_df= 
  mutate(
    homicide_df, citystate= str_c(city, state, sep= "-"),
    resolved= case_when(
      disposition== "Closed without arrest" ~ "unsolved",
      disposition== "Open/No arrest"~ "unsolved",
      disposition== "Closed by arrest"~ "solved"
    )
  )

```

## Problem 2

```{r}
#function
import= function(x){
  x_df= read_csv(x)%>%
    mutate(group_id= x)
  
  df= rbind(df, x_df)
}

#list of file names and map function
names= list.files(path = "data")
df_map= map_df(names, import, .id="order")


#tidy the output df
df_tidy= 
  separate(df_map, group_id, into= c("group", "id" ), sep= "_")%>%
  mutate(
    df_tidy, 
    group= factor(group, labels= c("control", "experiment")),
    id= factor(id, labels= c(1:10))
  )
  
df_tidy= df_tidy[, c(10,11,2:9)]



for (i in 1:10){
  df_plot_i=
    pull(df_tidy, col[1:2], col[i+2])%>%
    mutate(week=i)
  
  haha= rbind(haha, df_plot_i)
}
  

df_spaghetti= map_df(iteration, sub)
#plot
#ggplot(df_tidy, aes(x= , y=group_id, color= group_id))+
#  geom_point()+
#  geom_line()


```


## Problem 3

```{r}
#generate data set for mu=0
#function
sim_mean_p = function(samp_size, mean=0) {
  sim_data = 
    tibble(
      x = rnorm(n = samp_size, mean=mean, sd = 5)
    )
  
  sim_data %>% 
    summarize(
      mean = mean(x),
      sigma = sd(x)
    )%>%
    t.test() %>%
    broom::tidy()
}

output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_mean_p(30)%>%
    select(estimate, p.value)
}
sim_results = bind_rows(output)

```

```{r}
mu_list =
  list(
    "mu_1" = 1,
    "mu_2" = 2,
    "mu_3" = 3,
    "mu_4" = 4,
    "mu_5" = 5,
    "mu_6" = 6
  )

mu_list_output = vector("list", length = 6)

for (i in 1:6) {
mu_list_output[[i]] = rerun(5000, sim_mean_p(30, mean = mu_list[[i]])) %>% 
  bind_rows() %>% 
  select(estimate, p.value)
  
}

mu_value= vector(mode="integer", length=35000)
identifier= c(0,1,2,3,4,5,6)
mu_value= rep(identifier,c(5000,5000,5000,5000,5000,5000,5000))

#reorganize the dataframe for the first plot
graph_data =
bind_rows(sim_results, mu_list_output) %>%
  mutate(
    test_results = case_when(
      p.value < .05 ~ "reject",
      p.value >= .05 ~ "fail to reject"
    )
 
  )
plot_data= 
  bind_cols(graph_data, mu_value)

names(plot_data)[4]= "mu_val"

plot_data%>%
  count(mu_val, test_results)%>%
  mutate(rej_prop= n/sum(n))

#plot

mean_value= c(0,1,2,3,4,5,6)
reject_prop= c(0, 0.016, 0.172, 0.1136, 0.3488, 0.530,1991/5000)
bar_plot_data= data.frame(mean_value, reject_prop)

barplot(bar_plot_data,
        main="title",
        xlab= "mean_value", ylab= "reject_prop"
        )

#plot

plot_data%>%
  group_by(mu_val)%>%
  summarize(rej_prop= count(test_results= "reject")/5000)

p_value_plot= ggplot(plot_data)+
  geom_col(
    mapping= aes(mu_val~count(test_results= "reject"))
  )

p_value_plot

```
I could hardly plot the but from the cleaned data, we could see from the simulation, as $\mu$ grow from 0 to 6 the the probability of rejecting the null hypothesis grows exponentially. 

### the second plot

```{r}
plot2= ggplot(plot_data, aes(x= mu_val, y=estimate))+
  geom_point()
plot2

rejected= filter(plot_data, test_results== "reject", preserve= TRUE)
plot3= ggplot(rejected, aes(x=mu_val, y=estimate))+
  geom_point()
plot3
```




